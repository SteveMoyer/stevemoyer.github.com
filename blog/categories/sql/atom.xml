<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: sql | Coding Libetartian]]></title>
  <link href="http://blog.stevemoyer.net/blog/categories/sql/atom.xml" rel="self"/>
  <link href="http://blog.stevemoyer.net/"/>
  <updated>2013-03-12T14:16:54-07:00</updated>
  <id>http://blog.stevemoyer.net/</id>
  <author>
    <name><![CDATA[Steve Moyer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Breaking Down Unruly Databases: The Problem]]></title>
    <link href="http://blog.stevemoyer.net/2011/03/08/breaking-down-unruly-databases-problem.html"/>
    <updated>2011-03-08T00:05:00-08:00</updated>
    <id>http://blog.stevemoyer.net/2011/03/08/breaking-down-unruly-databases-problem</id>
    <content type="html"><![CDATA[<div class='post'>
In my <a href="http://blog.stevemoyer.net/2011/03/ndump-managing-development-and-test.html">last post</a> on <a href="https://github.com/SteveMoyer/nDump/wiki">nDump </a>I talked about a tool I've created to import and export data from MS SQL Server databases. &nbsp;In this post I want to lay out some of my motivation for doing so.<br />
<br />
Often when starting at a new client we arrive to find a legacy database/databases which seem nearly incomprehensible.  Development and CI often run against a shared databases which are backups of production.  The state of the data is in a constant flux. &nbsp;If someone desires to run a local database, restoring at least a few gigs of database backups is required.  One reason this is necessary is that the database(s) can't easily be recreated from scripts.  This is relatively easy to get around by breaking creation scripts into parts and employing tools such as <a href="http://dbdeploy.com/">DBDeploy</a> to run them in order.<br />
<br />
Once the problem of creating an empty database is tackled, nobody seems to have the requisite knowledge to populate it with the basic data necessary to run the application.  There are many problems that spring from a lack of the ability to create minimal data sets: <br />
<div><ol><li>Returning to a known data set is time consuming, requiring  restoring a large backup.</li>
<li>The development and functional test data sets can't be easily version-ed.  While you can check in a backup, there is no reasonable way to diff it against a previous version.</li>
<li>Functional tests are often brittle as they rely upon the state of the data which tends to be rather inconsistent.</li>
<li>Finding data requires searching through a large data set.</li>
<li>Deciphering incremental changes to the state of the data  is no small challenge.</li>
</ol><div>On past projects, the teams have stored development and test data sets as groups of csv or XML files.  Both of these files can be easily version-ed, diff-ed, and modified using excel or open office.  I prefer csv files as they are more concise and contain a lot less noise.&nbsp; Once you have these file sets and the requisite knowledge of the database structure it's relatively pleasant to work with them to maintain known state(s) of the data. By running the database build and load in a CI build we can continually verify that we know how to build a database. Using the populated database we can confirm that our functional tests of the application(s) are still working against a consistent data set. </div></div></div>


<h2>Comments</h2>


<div class='comments'>
<div class='comment'>
<div class='author'>Steve Moyer</div>
<div class='content'>
Hey Toast,<br />Thanks for the comment. I&#39;ve used a lot of the Red Gate Tools and found them helpful in more than a few situations.  Sql Storage Compress sounds interesting and addresses the copy and restore time.  It doesn&#39;t address lack of understanding of the database, having to deal with huge amounts of data, or versioning and diff-ing easily over time.<br />   Steve</div>
</div>
<div class='comment'>
<div class='author'>toast</div>
<div class='content'>
Hi!<br /><br />warning - about to plug a product from my current company...<br /><br />You can detach, copy, reattach a database if you want to quickly restore its contents to a known (saved) point. I guess you would then run your DB deploy scripts to update the schema appropriately.<br /><br />This need not use stupid amounts of disk space if you use something like (get ready for plug) Red Gate&#39;s SQL Storage Compress. That product can be used to compress your database files such that the copy command above takes less time (less to copy) and less disk. The database acts like normal when it is attached, it just happens to be 40% the size...<br /><br />of course, it costs money while your solution doesn&#39;t, but I think it would be worth checking out both SQL Virtual Restore and SQL Storage Compress.  www.red-gate.com</div>
</div>
</div>

]]></content>
  </entry>
  
</feed>
